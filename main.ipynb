{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run LanguageModel.py\n",
    "%run DataLoader.py\n",
    "%run rnn_utils.py\n",
    "%run encoder.py\n",
    "%run decoder.py\n",
    "%run seq2seq.py\n",
    "%run model_config.py\n",
    "%run metrics.py\n",
    "%run ScorePrinter.py\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader('train', ('de', 'en'), max_length = 50, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader('dev', ('de', 'en'), languageModels = train_dl.languageModels, max_length = 50, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 = train_dl.languageModels[train_dl.languages[0]]\n",
    "lm2 = train_dl.languageModels[train_dl.languages[1]]\n",
    "model_config = ModelConfig(input_size = lm1.n_tokens, beam_width = 3, hidden_size = 256, output_size = lm2.n_tokens, rnn_type='lstm', bidirectional=True, attention = 'global_context', score = 'dot', max_length=52)\n",
    "#checkpoint = torch.load(\"./state_dict.tar\")\n",
    "s2s = seq2seq(model_config=model_config, state_dict = None, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(epochs, print_every=1000):\n",
    "    n_iters = len(train_dl)\n",
    "    score_printer = ScorePrinter(\"Training\", [('NLL', loss_metric),('Perplexity', perplexity), ('BLEU', bleu)])\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        score_printer.startEpoch(epoch)\n",
    "        idx_permutation = np.random.permutation(len(train_dl))[:10000]\n",
    "\n",
    "        for i, index in enumerate(idx_permutation):\n",
    "            input_tensor, target_tensor = train_dl.tensorsFromPos(index)\n",
    "\n",
    "            loss, output_sentence = s2s.train(input_tensor, target_tensor)\n",
    "            real_target_sentence, estimated_target_sentence = train_dl.real_estimated_sentence(target_tensor, output_sentence)\n",
    "            score_printer.update(nll = loss, target_length = target_tensor.size(0), real_target_sentence=real_target_sentence, estimated_target_sentence=estimated_target_sentence)\n",
    "            \n",
    "            if (i + 1) % print_every == 0:\n",
    "                score_printer.printAvg(print_every)\n",
    "        \n",
    "        #score_printer.printAvg(len(train_dl))\n",
    "        val_avg_score = validate(100)\n",
    "        train_avg_score = score_printer.getAvgScores()\n",
    "        with open('./Validation_scores' + str(epoch) + '.txt', 'a') as validation_scores, open('./Training_scores' + str(epoch) + '.txt', 'a') as training_scores:\n",
    "            validation_scores.write(json.dumps(val_avg_score) + '\\n')\n",
    "            training_scores.write(json.dumps(train_avg_score) + '\\n')\n",
    "        #print(f\"Val_avg_score: {val_avg_score}, train_avg_score: {train_avg_score}\")\n",
    "        score_printer.endEpoch(epoch)\n",
    "        \n",
    "        torch.save(s2s.state_dict(),\"./state_dict_\"+str(epoch)+\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(n = None):\n",
    "    score_printer = ScorePrinter(\"Validation\", [('NLL', loss_metric),('Perplexity', perplexity), ('BLEU', bleu)])\n",
    "    n = n or len(val_dl)\n",
    "    idx_permutation_val = np.random.permutation(len(val_dl))[:n]\n",
    "    score_printer.beginMeasurements()\n",
    "    for j, val_index in enumerate(idx_permutation_val):\n",
    "        input_tensor_val, target_tensor_val = val_dl.tensorsFromPos(val_index)\n",
    "        loss, output_sentence = s2s.evaluate(input_tensor_val, target_tensor_val)\n",
    "        real_target_sentence, estimated_target_sentence = val_dl.real_estimated_sentence(target_tensor_val, output_sentence)\n",
    "        print(f\"real : {real_target_sentence}, est : {estimated_target_sentence}\")\n",
    "        score_printer.update(nll = loss, target_length = target_tensor_val.size(0), real_target_sentence  = real_target_sentence, estimated_target_sentence = estimated_target_sentence)\n",
    "    score_printer.printAvg(showCount = False)\n",
    "    return score_printer.getAvgScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs(5, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "def print_validation(position):\n",
    "    input_sentence = val_dl.sentenceFromTensor('de', val_dl.tensorsFromPos(position)[0])\n",
    "    display(Markdown('**Eingabe**'))\n",
    "    display(Markdown(' '.join(input_sentence)))\n",
    "    prediction = s2s.predict(val_dl.tensorsFromPos(position)[0])\n",
    "    output_sentence = val_dl.sentenceFromTensor('en', prediction[0])\n",
    "    display(Markdown('**Ausgabe**'))\n",
    "    display(Markdown(' '.join(output_sentence)))\n",
    "    attentions = torch.stack([tensor.squeeze() for tensor in prediction[2]])\n",
    "    attentions = attentions.numpy()[:len(output_sentence)-1,:len(input_sentence)]\n",
    "    display(Markdown('**Attention**'))\n",
    "    show_attention(input_sentence, output_sentence, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def show_attention(input_sentence, output_sentence, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(16, 14), dpi= 80)\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(input_sentence)))\n",
    "    ax.set_xticklabels(input_sentence, rotation=90)\n",
    "    ax.set_yticks(np.arange(len(output_sentence[1:])))\n",
    "    ax.set_yticklabels(output_sentence[1:]) # ignore SOS Token\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
